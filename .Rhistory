start <- as.Date("2018-10-16")
end <- as.Date("2018-10-17")
# Compile tweets from top gainers and losers
siuifTweets<-c(searchTwitter('$SIUIF ',n=100,lang = 'en',since = as.character(start),
until = as.character(end)))
gwwTweets<-c(searchTwitter('$GWW ',n=100,lang = 'en',since = as.character(start),
until = as.character(end)))
gwwTweets[[1]]
# Compile tweets from top gainers and losers
siuifTweets<-c(searchTwitter('SIUIF',n=100,lang = 'en',since = as.character(start),
until = as.character(end)))
# Compile tweets from top gainers and losers
cgcTweets<-c(searchTwitter('$CGC ',n=100,lang = 'en',since = as.character(start),
until = as.character(end)))
gwwTweets<-c(searchTwitter('$GWW ',n=100,lang = 'en',since = as.character(start),
until = as.character(end)))
rnweyTweets<-c(searchTwitter('$RNWEY ',n=100,lang = 'en',since = as.character(start),
until = as.character(end)))
acbffTweets<-c(searchTwitter('$ACBFF ',n=100,lang = 'en',since = as.character(start),
until = as.character(end)))
iTweets<-c(searchTwitter('$I ',n=100,lang = 'en',since = as.character(start),
until = as.character(end)))
arryTweets<-c(searchTwitter('$ARRY ',n=100,lang = 'en',since = as.character(start),
until = as.character(end)))
crispTweets<-c(searchTwitter('$crisp ',n=100,lang = 'en',since = as.character(start),
until = as.character(end)))
crspTweets<-c(searchTwitter('$CRSP ',n=100,lang = 'en',since = as.character(start),
until = as.character(end)))
crspTweets<-c(searchTwitter('$CRSP',n=100,lang = 'en',since = as.character(start),
until = as.character(end)))
arryTweets<-c(searchTwitter('$ARRY ',n=100,lang = 'en',since = as.character(start),
until = as.character(end)))
crspTweets<-c(searchTwitter('$PAGS ',n=100,lang = 'en',since = as.character(start),
until = as.character(end)))
crspTweets<-c(searchTwitter('$CRSP ',n=100,lang = 'en',since = as.character(start),
until = as.character(end)),
searchTwitter('#CRSP ',n=100,lang = 'en',since = as.character(start),
until = as.character(end)))
crspTweets<-c(searchTwitter('$CRSP ',n=100,lang = 'en',since = as.character(start),
until = as.character(end)),
searchTwitter('CRISPR Therapeutics',n=100,lang = 'en',since = as.character(start),
until = as.character(end)))
crspTweets<-c(searchTwitter('$CRSP ',n=100,lang = 'en',since = as.character(start),
until = as.character(end)),
searchTwitter('CRISPR Therapeutics',n=100,lang = 'en',since = as.character(start),
until = as.character(end)))
crspTweets<-c(searchTwitter('$CRSP ',n=100,lang = 'en',since = as.character(start),
until = as.character(end)),
searchTwitter('CRISPR Therapeutics',n=100,lang = 'en',since = as.character(start),
until = as.character(end)))
crspTweets<-c(searchTwitter('$CRSP ',n=100,lang = 'en')
)
cgcTweets<-searchTwitter('$CGC ',n=100,lang = 'en')
gwwTweets<-searchTwitter('$GWW ',n=100,lang = 'en')
crspTweets<-searchTwitter('$CRSP ',n=100,lang = 'en')
acbffTweets<-searchTwitter('$ACBFF ',n=100,lang = 'en')
iTweets<-searchTwitter('$I ',n=100,lang = 'en')
arryTweets<-searchTwitter('$ARRY ',n=100,lang = 'en')
# Check first tweets
cgcTweets[[1]]
gwwTweets[[1]]
crspTweets[[1]]
acbffTweets[[1]]
iTweets[[1]]
auTweets[[1]]
arryTweets[[1]]
#Simple function that removes usernames and creates corpus for tweets
createCorpus <- function (x) {Corpus(VectorSource(lapply(x, function(t) {t$getText()})))}
# Eliminate usernames in order to get only text from tweets
gwwTweets.text <- lapply(gwwTweets, function(t) {t$getText()})
# Text mine for each stock
gwwTweets.source <- VectorSource(gwwTweets.text)
gwwTweets.corpus <- Corpus(gwwTweets.source)
gwwTweets.corpus
# Inspect each corpus
inspect(gwwTweets.corpus[1])
secondGWW_corpus<-createCorpus(gwwTweets)
inspect(secondGWW_corpus[1])
secondGWW_corpus
gainerTweets<-c(gwwTweets,acbffTweets,cgcTweets)
gainerTweets[[1]]
gainerTweets[[101]]
gainerTweets[[201]]
iTweets<-searchTwitter('$I ',n=100,lang = 'en')
arryTweets<-searchTwitter('$ARRY ',n=100,lang = 'en')
crspTweets<-searchTwitter('$CRSP ',n=100,lang = 'en')
loserTweets<-c(iTweets,arryTweets,crspTweets)
# Check first tweets
gwwTweets[[1]]
gainerTweets[[1]]
crspTweets[[1]]
gainerTweets[[101]]
acbffTweets[[1]]
# Check first tweets
#Gainers
gwwTweets[[1]]
gainerTweets[[1]]
acbffTweets[[1]]
gainerTweets[[101]]
cgcTweets[[1]]
gainerTweets[[201]]
#Losers
iTweets[[1]]
loserTweets[[1]]
arryTweets[[1]]
loserTweets[[101]]
crspTweets[[1]]
loserTweets[[201]]
# Set directory
dir <- "C:/Users/pocke/OneDrive/Boston University/CS 688/Paul_Roche_Final_Project/"
setwd(dir)
# Import twitter API and access keys
source("twitter_keys.r")
#Setup authorization for API
setup_twitter_oauth(t.api.key,t.api.secret,t.access.key,t.access.secret)
# Compile tweets from top gainers and losers
#Top Losers
gwwTweets<-searchTwitter('$GWW ',n=100,lang = 'en')
acbffTweets<-searchTwitter('$ACBFF ',n=100,lang = 'en')
cgcTweets<-searchTwitter('$CGC ',n=100,lang = 'en')
#Combined gainers
gainerTweets<-c(gwwTweets,acbffTweets,cgcTweets)
#Top Gainers
iTweets<-searchTwitter('$I ',n=100,lang = 'en')
arryTweets<-searchTwitter('$ARRY ',n=100,lang = 'en')
crspTweets<-searchTwitter('$CRSP ',n=100,lang = 'en')
#Combined losers
loserTweets<-c(iTweets,arryTweets,crspTweets)
# Check first tweets
#Gainers
gwwTweets[[1]]
gainerTweets[[1]]
acbffTweets[[1]]
gainerTweets[[101]]
cgcTweets[[1]]
gainerTweets[[201]]
#Losers
iTweets[[1]]
loserTweets[[1]]
arryTweets[[1]]
loserTweets[[101]]
crspTweets[[1]]
loserTweets[[201]]
loserCorpus
# Eliminate usernames and text mine for each stock by using the createCorpus function
gainerCorpus<-createCorpus(gainerTweets)
loserCorpus<-createCorpus(loserTweets)
# Eliminate usernames and text mine for each stock by using the createCorpus function
gainerTweets.corpus<-createCorpus(gainerTweets)
loserTweets.corpus<-createCorpus(loserTweets)
# Eliminate usernames and text mine for each stock by using the createCorpus function
data.corpus1<-createCorpus(gainerTweets)
data.corpus2<-createCorpus(loserTweets)
#Simple function that removes usernames and creates corpus for tweets
createCorpus <- function (x) {Corpus(VectorSource(lapply(x, function(t) {t$getText()})))}
# Eliminate usernames and text mine for each stock by using the createCorpus function
data.corpus1<-createCorpus(gainerTweets)
data.corpus2<-createCorpus(loserTweets)
# Inspect each corpus
inspect(data.corpus1[1])
inspect(data.corpus2[1])
data.corpus1
data.corpus2
#Save corpus objects
save(data.corpus1, file = "gainersCorpuses.RData")
save(data.corpus2, file = "losersCorpuses.RData")
# Function that takes corpus and returns preprocessed corpus
preprocessCorpus <- function (corpus) {
# Remove url from tweets
removeURL <- function (x) { gsub(" ?(f|ht)tp(s?)://(.*)", "", gsub(" ?(f|ht)tp(s?)://\\S+ ", "", x)) }
# Preprocessing
corpus <- tm_map(corpus,content_transformer(removeURL)) # Remove URLs
corpus <- tm_map(corpus,removePunctuation) # Remove Punctuation
corpus <- tm_map(corpus, content_transformer(tolower)) # Lowercase
corpus <- tm_map(corpus, removeWords, stopwords("english")) # Remove stopwords
corpus <- tm_map(corpus, function(x) iconv(enc2utf8(x), sub = "byte")) # Remove emojis
}
# Perform preprocessing
data.corpus1<-preprocessCorpus(data.corpus1)
data.corpus2<-preprocessCorpus(data.corpus2)
?enc2native
# Create term document matrix for two sets of data: top gainers and top losers
# Create Document Term Matrix with word length >= 3 and >= 2 reps
# Document term matrix
dtm1 <- DocumentTermMatrix(data.corpus1, control=list(wordLengths=c(3,Inf), bounds=list(global=c(2,Inf)) ) )
dtm2 <- DocumentTermMatrix(data.corpus2, control=list(wordLengths=c(3,Inf), bounds=list(global=c(2,Inf)) ) )
# Find frequent terms
# losers:
losersTopWords<-findFreqTerms(dtm1,50)
losers.m<-as.matrix(dtm1)
losers.v<-sort(colSums(losers.m),decreasing = TRUE)
losers.top<-head(losers.v,50)
head(losers.top,10)
# gainers:
gainersTopWords<-findFreqTerms(dtm2,50)
gainers.m<-as.matrix(dtm2)
gainers.v<-sort(colSums(gainers.m),decreasing = TRUE)
gainers.top<-head(gainers.v,50)
head(gainers.top,10)
# Word Cloud
wordcloud(names(losers.top), freq = unname(losers.top),colors=brewer.pal(8, "Dark2"),
random.order = FALSE)
wordcloud(names(gainers.top), freq = unname(gainers.top),scale=c(3,.2),
random.order = FALSE,rot.per=.5,colors=brewer.pal(8, "Dark2"))
wordcloud(names(gainers.top), freq = unname(gainers.top),colors=brewer.pal(8, "Dark2"),
random.order = FALSE)
# Calculate Sentiment Score:
# Lexicons
pos.words = scan('positive-words.txt',what='character',comment.char=';')
neg.words = scan('negative-words.txt', what='character', comment.char=';')
#### Sentiment Analysis
#### Sentiment Analysis
sentiment <- function(text, pos.words, neg.words) {
text <- gsub('[[:punct:]]', '', text)
text <- gsub('[[:cntrl:]]', '', text)
text <- gsub('\\d+', '', text)
text <- tolower(text)
# split the text into a vector of words
words <- strsplit(text, '\\s+')
words <- unlist(words)
# find which words are positive
pos.matches <- match(words, pos.words)
pos.matches <- !is.na(pos.matches)
# find which words are negative
neg.matches <- match(words, neg.words)
neg.matches <- !is.na(neg.matches)
# calculate the sentiment score
score <- sum(pos.matches) - sum(neg.matches)
# cat (" Positive: ", words[pos.matches], "\n")
# cat (" Negative: ", words[neg.matches], "\n")
return (score)
}
losers.sent<-sentiment(lapply(loserTweets, function(t) {t$getText()}),pos.words,neg.words)
gainers.sent<-sentiment(lapply(gainerTweets, function(t) {t$getText()}),pos.words,neg.words)
barplot(c(losers.sent,gainers.sent), names.arg = c("Losers","Gainers"), xlab="Stock Type",
ylab="Sentiment Score",col="cyan",main="Stock Sentiment of Losers & Gainers",cex.names = 0.9)
# Inspect each corpus
inspect(data.corpus1[1])
inspect(data.corpus2[1])
inspect(data.corpus2[101])
#Combined Losers
loserTweets<-c(gwwTweets,acbffTweets,cgcTweets)
#Combined Gainers
gainerTweets<-c(iTweets,arryTweets,crspTweets)
# Check first tweets
#Gainers
gwwTweets[[1]]
loserTweets[[1]]
acbffTweets[[1]]
loserTweets[[101]]
cgcTweets[[1]]
loserTweets[[201]]
#Losers
iTweets[[1]]
gainerTweets[[1]]
arryTweets[[1]]
gainerTweets[[101]]
crspTweets[[1]]
gainerTweets[[201]]
#Simple function that removes usernames and creates corpus for tweets
createCorpus <- function (x) {Corpus(VectorSource(lapply(x, function(t) {t$getText()})))}
# Eliminate usernames and text mine for each stock by using the createCorpus function
data.corpus1<-createCorpus(loserTweets)
data.corpus2<-createCorpus(gainerTweets)
# Inspect each corpus
inspect(data.corpus1[1])
inspect(data.corpus2[101])
data.corpus1 #Losers
data.corpus2 #Gainers
#Save corpus objects
save(data.corpus1, file = "losersCorpuses.RData")
save(data.corpus2, file = "gainersCorpuses.RData")
# Function that takes corpus and returns preprocessed corpus
preprocessCorpus <- function (corpus) {
# Remove url from tweets
removeURL <- function (x) { gsub(" ?(f|ht)tp(s?)://(.*)", "", gsub(" ?(f|ht)tp(s?)://\\S+ ", "", x)) }
# Preprocessing
corpus <- tm_map(corpus,content_transformer(removeURL)) # Remove URLs
corpus <- tm_map(corpus,removePunctuation) # Remove Punctuation
corpus <- tm_map(corpus, content_transformer(tolower)) # Lowercase
corpus <- tm_map(corpus, removeWords, stopwords("english")) # Remove stopwords
corpus <- tm_map(corpus, function(x) iconv(enc2utf8(x), sub = "byte")) # Remove emojis
}
# Perform preprocessing
data.corpus1<-preprocessCorpus(data.corpus1)
data.corpus2<-preprocessCorpus(data.corpus2)
# Create term document matrix for two sets of data: top gainers and top losers
# Create Document Term Matrix with word length >= 3 and >= 2 reps
# Document term matrix
dtm1 <- DocumentTermMatrix(data.corpus1, control=list(wordLengths=c(3,Inf), bounds=list(global=c(2,Inf)) ) )
dtm2 <- DocumentTermMatrix(data.corpus2, control=list(wordLengths=c(3,Inf), bounds=list(global=c(2,Inf)) ) )
# Find frequent terms
# losers:
losersTopWords<-findFreqTerms(dtm1,50)
losers.m<-as.matrix(dtm1)
losers.v<-sort(colSums(losers.m),decreasing = TRUE)
losers.top<-head(losers.v,50)
head(losers.top,10)
# gainers:
gainersTopWords<-findFreqTerms(dtm2,50)
gainers.m<-as.matrix(dtm2)
gainers.v<-sort(colSums(gainers.m),decreasing = TRUE)
gainers.top<-head(gainers.v,50)
head(gainers.top,10)
# Word Cloud
wordcloud(names(losers.top), freq = unname(losers.top),colors=brewer.pal(8, "Dark2"),
random.order = FALSE)
wordcloud(names(gainers.top), freq = unname(gainers.top),colors=brewer.pal(8, "Dark2"),
random.order = FALSE)
# Calculate Sentiment Score:
# Lexicons
pos.words = scan('positive-words.txt',what='character',comment.char=';')
neg.words = scan('negative-words.txt', what='character', comment.char=';')
#### Sentiment Analysis
#### Sentiment Analysis
sentiment <- function(text, pos.words, neg.words) {
text <- gsub('[[:punct:]]', '', text)
text <- gsub('[[:cntrl:]]', '', text)
text <- gsub('\\d+', '', text)
text <- tolower(text)
# split the text into a vector of words
words <- strsplit(text, '\\s+')
words <- unlist(words)
# find which words are positive
pos.matches <- match(words, pos.words)
pos.matches <- !is.na(pos.matches)
# find which words are negative
neg.matches <- match(words, neg.words)
neg.matches <- !is.na(neg.matches)
# calculate the sentiment score
score <- sum(pos.matches) - sum(neg.matches)
# cat (" Positive: ", words[pos.matches], "\n")
# cat (" Negative: ", words[neg.matches], "\n")
return (score)
}
losers.sent<-sentiment(lapply(loserTweets, function(t) {t$getText()}),pos.words,neg.words)
gainers.sent<-sentiment(lapply(gainerTweets, function(t) {t$getText()}),pos.words,neg.words)
barplot(c(losers.sent,gainers.sent), names.arg = c("Losers","Gainers"), xlab="Stock Type",
ylab="Sentiment Score",col="cyan",main="Stock Sentiment of Losers & Gainers",cex.names = 0.9)
#Save objects
save(dtm1,dtm2,file = "gainersLosersDTMs.RData")
library(googleVis)
#Get stock data and plot it
allStocks<-c("CGC","GWW","ACBFF","CRSP","I","AU","ARRY")
getSymbols(allStocks,src = "yahoo")
chartSeries(CGC,type = "candlesticks",subset = '2018-10-08::2018-10-12',
up.col = "green",dn.col = "red",TA=NULL)
#googleVis
#Line Chart Visualization
lineChart<-gvisLineChart(CGC,options=list(width=700, height=200))
#googleVis
#Line Chart Visualization
lineChart<-gvisLineChart(as.data.frame(CGC),options=list(width=700, height=200))
plot(lineChart)
head(as.data.frame(CGC))
gvisAnnotatedTimeLine(CGC)
gvisAnnotationChart(CGC)
gvisAnnotatedTimeLine(as.data.frame(CGC))
plot(gvisAnnotatedTimeLine(as.data.frame(CGC)))
plot(gvisAnnotationChart(CGC))
plot(gvisAnnotatedTimeLine(CGC))
## Not run:
## Plot Apple's monthly stock prices since 1984
## Get current date
d <- Sys.time()
current.year <- format(d, "%Y")
current.month <- format(d, "%m")
current.day <- format(d, "%d")
## Yahoo finance sets January to 00 hence:
month <- as.numeric(current.month) - 1
month <- ifelse(month < 10, paste("0",month, sep=""), m)
## Get weekly stock prices from Apple Inc.
tckr <- 'AAPL'
yahoo <- 'http://ichart.finance.yahoo.com/table.csv'
fn <- sprintf('%s?s=%s&a=08&b=7&c=1984&d=%s&e=%s&f=%s&g=w&ignore=.csv',
yahoo, tckr, month, current.day, current.year)
## Get data from Yahoo! Finance
data <- read.csv(fn, colClasses=c("Date", rep("numeric",6)))
AAPL <- reshape(data[,c("Date", "Close", "Volume")], idvar="Date",
times=c("Close", "Volume"),
timevar="Type",
varying=list(c("Close", "Volume")),
v.names="Value",
direction="long")
## Calculate previous two years for zoom start time
lyd <- as.POSIXlt(as.Date(d))
lyd$year <- lyd$year-2
lyd <- as.Date(lyd)
aapl <- gvisAnnotationChart(AAPL, datevar="Date",
numvar="Value", idvar="Type",
options=list(
colors="['blue', 'lightblue']",
22 gvisAreaChart
zoomStartTime=lyd,
zoomEndTime=as.Date(d),
legendPosition='newRow',
width=600, height=400, scaleColumns='[0,1]',
scaleType='allmaximized')
)
## Not run:
## Plot Apple's monthly stock prices since 1984
## Get current date
d <- Sys.time()
current.year <- format(d, "%Y")
current.month <- format(d, "%m")
current.day <- format(d, "%d")
## Yahoo finance sets January to 00 hence:
month <- as.numeric(current.month) - 1
month <- ifelse(month < 10, paste("0",month, sep=""), m)
## Get weekly stock prices from Apple Inc.
tckr <- 'AAPL'
yahoo <- 'http://ichart.finance.yahoo.com/table.csv'
fn <- sprintf('%s?s=%s&a=08&b=7&c=1984&d=%s&e=%s&f=%s&g=w&ignore=.csv',
yahoo, tckr, month, current.day, current.year)
## Get data from Yahoo! Finance
data <- read.csv(fn, colClasses=c("Date", rep("numeric",6)))
chartSeries(CGC,type = "candlesticks",subset = '2018-10-03::2018-10-17',
up.col = "green",dn.col = "red",TA=NULL)
chartSeries(GWW,type = "candlesticks",subset = '2018-10-03::2018-10-17',
up.col = "green",dn.col = "red",TA=NULL)
chartSeries(ACBFF,type = "candlesticks",subset = '2018-10-03::2018-10-17',
up.col = "green",dn.col = "red",TA=NULL)
chartSeries(CRSP,type = "candlesticks",subset = '2018-10-03::2018-10-17',
up.col = "green",dn.col = "red",TA=NULL)
chartSeries(I,type = "candlesticks",subset = '2018-10-03::2018-10-17',
up.col = "green",dn.col = "red",TA=NULL)
chartSeries(ARRY,type = "candlesticks",subset = '2018-10-03::2018-10-17',
up.col = "green",dn.col = "red",TA=NULL)
typeof(CGC)
as.data.frame(CGC)
#googleVis
#Line Chart Visualization
lineChart<-gvisLineChart(as.data.frame(CGC)$CGC.Close,options=list(width=700, height=200))
as.data.frame(CGC)$CGC.Close
as.data.frame(CGC)[4]
lineChart<-gvisLineChart(CGC[4],options=list(width=700, height=200))
lineChart<-gvisLineChart(as.data.frame(CGC)[4],options=list(width=700, height=200))
as.data.frame(CGC)[4]
lineChart<-gvisLineChart(c(as.data.frame(CGC)[4],names(as.data.frame(CGC))),options=list(width=700, height=200))
c(as.data.frame(CGC)[4],names(as.data.frame(CGC)))
losers.top
as.matrix(CGC)
#googleVis
#Line Chart Visualization
#makeStockChart <- function (x) {
lineChart<-gvisLineChart(c(as.data.frame(CGC)[4],row.names(as.data.frame(CGC))),options=list(width=700, height=200))
data.frame(as.data.frame(CGC)[4],row.names(as.data.frame(CGC)))
#googleVis
#Line Chart Visualization
#makeStockChart <- function (x) {
lineChart<-gvisLineChart(data.frame(as.data.frame(CGC)[4],row.names(as.data.frame(CGC))),options=list(width=700, height=200))
plot(lineChart)
#googleVis
#Line Chart Visualization
#makeStockChart <- function (x) {
lineChart<-gvisLineChart(row.names(as.data.frame(CGC)),data.frame(as.data.frame(CGC)[4])),options=list(width=700, height=200))
#googleVis
#Line Chart Visualization
#makeStockChart <- function (x) {
lineChart<-gvisLineChart(row.names(as.data.frame(CGC)),data.frame(as.data.frame(CGC)[4]))options=list(width=700, height=200))
#googleVis
#Line Chart Visualization
#makeStockChart <- function (x) {
lineChart<-gvisLineChart(data.frame(row.names(as.data.frame(CGC)),as.data.frame(CGC)[4])), options=list(width=700, height=200))
#googleVis
#Line Chart Visualization
#makeStockChart <- function (x) {
lineChart<-gvisLineChart(data.frame(row.names(as.data.frame(CGC)),as.data.frame(CGC)[4]), options=list(width=700, height=200))
plot(lineChart)
#googleVis
#Line Chart Visualization
makeStockChart <- function (x) {
lineChart<-gvisLineChart(data.frame(row.names(as.data.frame(x)),as.data.frame(x)[4]), options=list(width=700, height=200))
}
plot(makeStockChart(CGC))
data.frame(row.names(as.data.frame(x)),as.data.frame(x)[4])
head(data.frame(row.names(as.data.frame(CGC)),as.data.frame(CGC)[4]))
makeStockChart <- function (x) {
lineChart<-gvisLineChart(data.frame(row.names(as.data.frame(x)),as.data.frame(x)[4]),
options=list(width=700, height=200))
}
Date2<-as.Date(row.names(as.data.frame(CGC)))
stockDF<-(data.frame(Date2,as.data.frame(CGC)[4]))
stockDF<-subset(stockDF,Date2>"2018-10-03")
plot(makeStockChart(CGC))
plot(makeStockChart(stockDF))
plot(visLineChart(stockDF))
plot(gvisLineChart(stockDF))
plot(makeStockChart(I)
plot(makeStockChart(I))
#googleVis
#Line Chart Visualization
makeStockChart <- function (x) {
lineChart<-gvisLineChart(subset((data.frame(as.Date(row.names(as.data.frame(x))),as.data.frame(x)[4])),as.Date(row.names(as.data.frame(x)))>"2018-10-03"),options=list(width=500, height=200))
}
plot(makeStockChart(I))
#googleVis
#Line Chart Visualization
makeStockChart <- function (x) {
lineChart<-gvisLineChart(subset((data.frame(as.Date(row.names(as.data.frame(x))),
as.data.frame(x)[4])),
as.Date(row.names(as.data.frame(x)))>"2018-10-03"),
options=list(width=700, height=250))
}
plot(makeStockChart(I))
#Merge visualizations for all in one display
mergeChart1<-gvisMerge(makeStockChart(CGC),makeStockChart(GWW))
losersMerged<-gvisMerge(mergeChart1,makeStockChart(ACBFF))
mergeChart2<-gvisMerge(makeStockChart(CRSP),(makeStockChart(I)))
gainersMerged<-gvisMerge(mergeChart2, makeStockChart(ARRY))
finalMerged<-gvisMerge(losersMerged,gainersMerged,horizontal=TRUE)
plot(finalMerged)
